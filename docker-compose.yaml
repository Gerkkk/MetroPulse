version: '3'

services:
  oltp-db:
    image: postgres:16
    container_name: oltp-db
    environment:
      POSTGRES_DB: oltp
      POSTGRES_USER: user
      POSTGRES_PASSWORD: password
    ports:
      - "5433:5432"
    volumes:
      - oltp_data:/var/lib/postgresql/data
      - ./oltp/migrations:/docker-entrypoint-initdb.d
      - ./oltp/postgresql.conf.override:/etc/postgresql/postgresql.conf
    command: >
      postgres
      -c config_file=/etc/postgresql/postgresql.conf
      -c max_prepared_transactions=100
    healthcheck:
      test: [ "CMD", "pg_isready", "-U", "user", "-d", "oltp"]
      interval: 5s
      timeout: 5s
      retries: 5
    networks:
      app-net:

  zookeeper:
    container_name: zookeeper
    image: confluentinc/cp-zookeeper:7.4.4
    ports:
      - "2181:2181"
    environment:
      - ALLOW_ANONYMOUS_LOGIN=yes
      - ZOOKEEPER_CLIENT_PORT=2181
      - ZOOKEEPER_TICK_TIME=2000
    networks:
      - kafka-net
      - app-net
    healthcheck:
      test: [ "CMD", "bash", "-c", "echo stat | nc localhost 2181" ]
      interval: 10s
      timeout: 5s
      retries: 10

  kafka:
    image: confluentinc/cp-kafka:7.4.4
    container_name: kafka
    ports:
      - "9092:9092"
      - "29092:29092"
    environment:
      - KAFKA_ZOOKEEPER_CONNECT=zookeeper:2181
      - KAFKA_LISTENERS=PLAINTEXT://:9092,EXTERNAL://:29092
      - KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://kafka:9092,EXTERNAL://host.docker.internal:29092
      - KAFKA_LISTENER_SECURITY_PROTOCOL_MAP=PLAINTEXT:PLAINTEXT,EXTERNAL:PLAINTEXT
      - KAFKA_INTER_BROKER_LISTENER_NAME=PLAINTEXT
      - KAFKA_AUTO_CREATE_TOPICS_ENABLE=true
      - KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR=1
      - KAFKA_CREATE_TOPICS="vehicle_positions:1:1"
    depends_on:
      zookeeper:
        condition: service_healthy
    healthcheck:
      test: [ "CMD", "kafka-topics", "--bootstrap-server", "localhost:9092", "--list" ]
      interval: 10s
      timeout: 10s
      retries: 10
    volumes:
      - ./kafka/scripts/create-topics.sh:/tmp/create-topics.sh
    command: >
      sh -c "
      /etc/confluent/docker/run &
      sleep 20 &&
      chmod +x /tmp/create-topics.sh &&
      /tmp/create-topics.sh &&
      wait
      "
    networks:
      - kafka-net
      - app-net

  kafka-ui:
    image: provectuslabs/kafka-ui:latest
    container_name: kafka-ui
    ports:
      - "8085:8080"
    environment:
      - KAFKA_CLUSTERS_0_NAME=local
      - KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS=kafka:9092, localhost:9092, localhost:29092
    depends_on:
      - kafka
    networks:
      - kafka-net
      - app-net

  generator:
    build:
      context: .
      dockerfile: generator/Dockerfile
    ports:
      - "9090:9090"
    volumes:
      - ./configs:/app/configs
    networks:
      app-net:
    depends_on:
      oltp-db:
        condition: service_healthy
      kafka:
        condition: service_healthy

  minio:
    image: minio/minio
    container_name: minio
    command: server /data --console-address :9001
    ports:
      - "19000:9000"
      - "19001:9001"
    environment:
      MINIO_ROOT_USER: admin
      MINIO_ROOT_PASSWORD: admin1234
    volumes:
      - ./minio/data:/data
    networks:
      app-net:
    depends_on:
      oltp-db:
        condition: service_healthy
      kafka:
        condition: service_healthy
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:9000/minio/health/live" ]
      interval: 5s
      timeout: 3s
      retries: 5

  minio-mc-setup:
    image: minio/mc
    depends_on:
      minio:
        condition: service_healthy
    entrypoint: >
      sh -c "
      mc alias set localminio http://minio:9000 admin admin1234 &&
      mc mb localminio/kafka/payments &&
      mc mb localminio/kafka/rides &&
      mc mb localminio/kafka/routes &&
      mc mb localminio/kafka/users &&
      mc mb localminio/kafka/vehicles &&
      mc mb localminio/kafka/vehicle_positions
      "
    networks:
      - app-net

  spark-staging:
    build:
      context: sparks
      dockerfile: Dockerfile
      args:
        - PREINSTALLED_PACKAGES=org.apache.hadoop:hadoop-aws:3.4.2,software.amazon.awssdk:s3:2.25.53,org.postgresql:postgresql:42.7.7
    container_name: spark-staging
    environment:
      - SPARK_PACKAGES=org.apache.hadoop:hadoop-aws:3.4.2,software.amazon.awssdk:s3:2.25.53,org.postgresql:postgresql:42.7.7
      - ADDITIONAL_FLAGS=--driver-class-path postgresql-9.4.1207.jar --jars postgresql-9.4.1207.jar
    volumes:
      - ./sparks/sparkStaging:/opt/spark/scripts
      - ./sparks/sparkStaging/config.cfg:/opt/spark/config.cfg
    networks:
      app-net:

  greenplum:
    build:
      context: ./greenplum
      dockerfile: Dockerfile
    container_name: dwh
    hostname: dwh
    expose:
      - "5432"
    ports:
      - "5432:5432"
    volumes:
      - dwh-data:/data
      - ./greenplum/migrations:/migrations
    networks:
      app-net:
    restart: unless-stopped
  
  clickhouse:
    image: clickhouse/clickhouse-server:latest
    container_name: clickhouse
    hostname: clickhouse
    ports:
      - "8123:8123"
      - "29000:9000"
    environment:
      - CLICKHOUSE_DB=analytics
      - CLICKHOUSE_USER=admin
      - CLICKHOUSE_PASSWORD=admin123
      - CLICKHOUSE_DEFAULT_ACCESS_MANAGEMENT=1
    ulimits:
      nofile:
        soft: 262144
        hard: 262144
    volumes:
      - ./clickhouse_data:/var/lib/clickhouse
      - ./clickhouse_logs:/var/log/clickhouse-server
    networks:
      - app-net
    restart: unless-stopped

  spark-gp-to-click:
    build:
      context: sparks
      dockerfile: Dockerfile
      args:
        PREINSTALLED_PACKAGES: "org.postgresql:postgresql:42.7.7,com.clickhouse:clickhouse-jdbc:0.9.5"
    container_name: spark-gp-to-click
    environment:
      SPARK_PACKAGES: "org.postgresql:postgresql:42.7.7,com.clickhouse:clickhouse-jdbc:0.9.5"
    volumes:
      - ./sparks/sparkGpToClick:/opt/spark/scripts
      - ./clickhouse/queries:/opt/spark/queries
      - ./sparks/sparkGpToClick/config.cfg:/opt/spark/config.cfg
    networks:
      app-net:


  kafka-connect:
    image: debezium/connect:2.6
    container_name: kafka-connect
    depends_on:
      - kafka
      - oltp-db
    ports:
      - "8083:8083"
    environment:
      BOOTSTRAP_SERVERS: kafka:9092
      GROUP_ID: 1
      CONFIG_STORAGE_TOPIC: connect_configs
      OFFSET_STORAGE_TOPIC: connect_offsets
      STATUS_STORAGE_TOPIC: connect_statuses

      KEY_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      VALUE_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      VALUE_CONVERTER_SCHEMAS_ENABLE: "false"
      KEY_CONVERTER_SCHEMAS_ENABLE: "false"

      REST_ADVERTISED_HOST_NAME: kafka-connect
    volumes:
      - connect-data:/kafka/connect
    networks:
      - kafka-net
      - app-net
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:8083/connectors" ]
      interval: 10s
      timeout: 5s
      retries: 5

  register-connectors:
    build:
      context: .
      dockerfile: dockerfiles/register.Dockerfile
    container_name: register-connectors
    depends_on:
      kafka-connect:
        condition: service_healthy
    networks:
      - app-net


volumes:
  oltp_data:
  connect-data:
  dwh-data:

networks:
  kafka-net:
    driver: bridge
  app-net:
    driver: bridge
